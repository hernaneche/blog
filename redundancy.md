Redundancy In Programming Languages   

_"Everything should be made as simple as possible, but not simpler."_-A. Einstein

**Minimalism And Redundancy**  

Exact sciences writing can have a very low resilience, a single mistake in a equation sign can lead to totally wrong results, paradoxically this fragility is brought by minimalism, which mathematicians pursue.
So, how to prevent single failures from tearing down a whole system ? The obvious trick for resilience is propagation, i.e. distributed replication, it's like making a backup of data and putting copies in different places, this is not the same thing as making data larger; because it's the same data which spreads, the aim is to keep conceptual minimalism, gaining resilience while preserving the name and the work behind it, that's more or less the idea, that any data pattern could be propagated independent of _how_ the storing/communication is implemented for it, so _adding a layer with some level of redundancy fosters resilience in the upper layer_.  
For example in safety-critical systems some parts may be triplicated, all three working in parallel doing just the same, so the output is not decided by none of them alone but by a quorum scheme (a two of three voting system), if one of those part fails the system will decide right anyway, avoiding sporadic failures effects and giving time to find the cause; a similar technique is to have spare parts of vital subsystems connected and ready to work as Redundancy, so they can auto-replace a failing partner without human intervention (for example when a power supply fails, a second one could replaces it on the fly, preventing the system shutdown, and again allowing time to review the cause of the first failure). Note that these techniques could be independent of what the system design/functionality is, we could have started with an already efficient but fragile design of a system and _then_ add some redundancy designed and thought as an independent layer.  

**Computer Things**  

Computer Programs do have low redundancy, if we choose to type random characters when programming a source code, we will get into a bug with a very high probability! (perhaps it won't even compile, at the best of cases), programming languages often have a poor [Hamming distance](http://en.wikipedia.org/wiki/Hamming_distance) between any intended functional code and any bug, and this low redundancy is partly _intentional_ ([DRY Principle](http://en.wikipedia.org/wiki/Don%27t_repeat_yourself)), so except for things like names, spacing, comments.. the source code itself is fragile, and besides the functionality layer, we try to have the most compact (yet readable) source code representation, redundancy within the code can sometimes be viewed as a cause of future problems, because as software evolves (as it -probably- will) it becomes necessary to make changes to it, we want changes to be localized, i.e. for doing changes about a single feature, we want to edit only a single place, and once (keep the spread to a minimum). This is a very weird goal to have, why? because we want a system to be ready for our "intentional" changes, to be Easy to control and change by "us", but at the same time, we want it to be Hard to change by any "unintended" means, like noises, errors, hardware problems, other people, etc. It's kind of asking a system to be able to know what changes are intended by us and which ones are unintended, what we are willing to have seems to be a system that knows future in advance, even to know us in advance, a system that "encodes our will", as an extension of us, a system that reflex _our_ desires over time without telling them, it's paradoxical and kind of crazy to ask a system for knowing what we intent, being that sometimes not even we know it!.  
It's usual to define certain sanity criteria, and implement the feature of avoiding "unintended" changes (but only in the sense of those criteria!), in data systems this is known as ECC(Error-Correcting Codes), and there are a lot of algorithms about how to introduce enough redundancy within data to recover it from some errors against some criteria, but if criteria changes, we are again in problems. Even a [revision control system](http://en.wikipedia.org/wiki/Git_%28software%29) is a high level way of adding resilience to a software project, more so important for developing projects that change through time, namely, any project.  
As all of those schemes are a separate layer of data, i.e. they modify the data format in a way it loses his original coding then it can't be parsed directly as if it where the raw data source, but first it has to pass through an encoder/decoder that recover backups, checks, sanitize, decode and so on with respect of some resilience criteria.  

**Human Things**  

Here things are quite different, if you take a Law book, or a Novel and write down some random characters within their pages, they would perhaps still be readable, and even the meaning of the work would remain unchanged. In a 1950 paper "Prediction and Entropy of Printed English" Claude Shannon found english text to be 75% redundant in a specific sense, that same information contained in a word or a sentence can be inferred by using just some related letters (as [text phone language](http://en.wikipedia.org/wiki/SMS_language) has shown), of course, that redundancy could only be useful if the reader knows in advance the statistical distribution of letters, words, sentences, etc. Even knowing english words only, it would be enough to make predictions at word level, but not at sentence level, nor at paragraph level there are other probabilities for every level, so on a History book an Historian would do better predictions(and error-corrections), on a Math book a Mathematician would do it better, and so on. The prior general knowledge about the language let us predict and correct syntax errors, the prior kwnowledge about the subject allows to predict and correct sentences and global errors (because how an error is defined, is something relative to the field or domain of knowledge).  
Resilience in human communication can be traced in the redundancy of evolved languages, its long words, grammatical rules, sentences, context, and so on, but it's a human understanding merit too, we do a good job as interpreters (and this is a double-edged sword, while it's difficult to ask a computer program to parse some data, it's impossible to ask a human NOT to interpret data!...["don't think on an elephant"](http://en.wikipedia.org/wiki/Ironic_process_theory)) so making better programming languages is about getting better grammar and better compilers/interpreters, then resilience is defined not only within the syntax but by the interpreter too, both compose a self healing feature that could overcome the presence of noise and mistakes. Talking about redundancy in human language is a too narrow way of see it, redundancy on a human message implies much more than resilience, it's part of the message too, human protocols are much more complex than resilience alone, anyway redundancy is there.  

**Monkey Things**  

Let's imagine a representation of this issue about propagation of same data, imagine a control system of a big dam in a river near a jungle, the system is capable of open or close dam's gates, and depending on rainfall a bad decision on it could lead to flooding. To be practical and fast enough the system can open or close ALL dam gates from a single switch in the control box, but having a jungle around has some side effects like monkeys bothering around, and even a single monkey entering at night through a window could turn the main switch and produce a flood. To avoid this problem, we need the system to be monkey-resistant, as we saw, to gain resilience as usual is to add some kind of multiplicity, to spread it, so for example instead of having only one switch to bring them all, we could install three individual switches one for every gate, we could even ask for all switch to be turned within a time interval to produce the all-gate movement, this would transform the incident from being probable to be as unlikely as having monkeys moving three switchs at near the same time. This will increase system safety at expenses of making the operator task harder. But if we want to command same system from a remote location and more secure area, for example a cell phone or a comfortable office building in a city (away from monkeys) then the three switch system could be not necessary, system could be triggered by a single switch (leading now the resilience to communication). This new one visible controllable "intention" button is a layer to manage a hidden multiplicity only accessible from the "intended" zone, it hides complexity, and let control system out of reach of the "unintended" zone. We can hide it **because** we can control it. The brittleness (and then the severity of some dangers) could be diluted by propagation, multiplicity and diversity (as different techniques, or simply different locations), this is to gain resilience at the expense of complexity growing over the system, and that complexity is not for free, it has to be managed too and this could be seen as a new danger, because it wouldn't be any gain if we just exchange the culprit of the accident, from a monkey to stressed workers, designers, programmers, but the trick is that they can be more in number, and they can be organized too, then this hierarchical distribution of work can be viewed socially as the distribution (and consequent dilution) of each individual/subsystem danger, and then the enhancement of resilience for the whole system, workers, users and for everyone. Hierarchy organization could seem to be _caused_ by component limits, but it's also made to overcome them. And as the system will evolve with time, it's important to keep track of that distribution, it should be adapted adding multiplicity to avoid a processing overload on any component, if any part have too much responsibility for the whole then everyone is harm. Minimizing responsibility of every component leads to a better system design (in the strict sense of gaining more power while keeping alive through time), but perhaps losing power of individual components is not a shared intention, especially if "components" are humans.  

**Strange Things**  

Finally, here is a curiosity to note, Human written languages have redundancy in it's own encoding layer, i.e. in written text there are syntax clues, grammatical clues, and even semantic clues that let us fix errors and to guess what is intended to be said (depending on our prior knowledge and skills), but there is no explicit encoder/decoder mechanism. It's like if we are parsing many layer at once, there are no intermediate translation (at least no a conscious one). We speak redundancy indistinguishable from data, they are composed together, and we have no explicit datatype field in our text, still a picture is worth a thousand words, i.e. there are things outside our language.
